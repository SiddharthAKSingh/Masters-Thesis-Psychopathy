{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHD8lwVKeT4P",
        "outputId": "baf59db2-e92e-40a7-9c9a-5bdd32746f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "current_dir = \"gdrive/My Drive/Colab Notebooks/Thesis/gold_standard\"\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pickle\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression,\n",
        "    Ridge,\n",
        "    Lasso,\n",
        "    ElasticNet,\n",
        "    PoissonRegressor,\n",
        "    LogisticRegression,)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor ,GradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(current_dir)"
      ],
      "metadata": {
        "id": "fQGUld4VgKYa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('enriched_dataframe.pkl', 'rb') as file:\n",
        "    data  = pickle.load(file)"
      ],
      "metadata": {
        "id": "jglV5g0JImy6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRegressionModel:\n",
        "    def __init__(self, train_data, target_column, text_column, vectorizer = None, model=None):\n",
        "        self.train_data = train_data\n",
        "        self.target_column = target_column\n",
        "        self.text_column = text_column\n",
        "        self.model = Ridge() if model is None else model\n",
        "        self.vectorizer = CountVectorizer() if vectorizer is None else vectorizer\n",
        "        self.results_df = None\n",
        "        self.data_list = []\n",
        "        self.feature_importance_list = []\n",
        "\n",
        "\n",
        "    def vectorize_text(self):\n",
        "        X = self.vectorizer.fit_transform(self.train_data[self.text_column])\n",
        "        self.feature_names = self.vectorizer.get_feature_names_out()\n",
        "        return X\n",
        "\n",
        "    def perform_loocv(self):\n",
        "        X = self.vectorize_text()\n",
        "        y = self.train_data[self.target_column]\n",
        "        loo = LeaveOneOut()\n",
        "        for train_index, test_index in loo.split(X):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "            names_test = self.train_data['name'].iloc[test_index]\n",
        "\n",
        "            if hasattr(self.model, \"requires_dense\") and self.model.requires_dense:\n",
        "              X_train = X_train.toarray()\n",
        "              X_test = X_test.toarray()\n",
        "\n",
        "\n",
        "            self.model.fit(X_train, y_train)\n",
        "\n",
        "            y_pred = self.model.predict(X_test)\n",
        "\n",
        "            for name, predicted, actual in zip(names_test, y_pred, y_test):\n",
        "                self.data_list.append({'name': name, 'predicted': predicted, 'actual': actual, 'difference': predicted - actual})\n",
        "            try:\n",
        "              split_feature_importance = self.model.coef_\n",
        "              feature_importance_dict = {\n",
        "                  'test_sample_name': names_test.iloc[0],\n",
        "                  'feature_importance': {\n",
        "                      token: importance for token, importance in zip(self.feature_names, split_feature_importance) if abs(importance) > 0\n",
        "                  }\n",
        "              }\n",
        "              self.feature_importance_list.append(feature_importance_dict)\n",
        "            except:\n",
        "              pass\n",
        "\n",
        "        self.results_df = pd.DataFrame(self.data_list)\n",
        "        self.results_df['MAE'] = self.results_df['difference'].abs()\n",
        "        return\n",
        "\n",
        "\n",
        "    def get_coefficients(self):\n",
        "        # Initialize a dictionary to count the frequency of each token\n",
        "        token_frequency = {}\n",
        "\n",
        "        for split_info in self.feature_importance_list:\n",
        "            for token in split_info['feature_importance']:\n",
        "                # Count the frequency of each token across different models\n",
        "                if token in token_frequency:\n",
        "                    token_frequency[token] += 1\n",
        "                else:\n",
        "                    token_frequency[token] = 1\n",
        "\n",
        "        # Sort tokens by their frequency in descending order\n",
        "        top_tokens = sorted(token_frequency, key=token_frequency.get, reverse=True)\n",
        "\n",
        "        # Print the top tokens and their feature importance in each model\n",
        "        for token in top_tokens:\n",
        "            # Create a list of importances for each test sample where the token appears\n",
        "            token_importances_list = [split_info['feature_importance'][token]\n",
        "                                      for split_info in self.feature_importance_list if token in split_info['feature_importance']]\n",
        "\n",
        "            # Calculate the average importance for the token\n",
        "            average_importance = sum(token_importances_list) / len(token_importances_list)\n",
        "\n",
        "            print(f\"\\nToken: {token} \\nTop performing feature in {token_frequency[token]}/10 models | Average Strength: {average_importance}\")\n",
        "\n",
        "            # Create a list of tuples (test_sample_name, importance) for each test sample where the token appears\n",
        "            token_importances = [(split_info['test_sample_name'], split_info['feature_importance'][token])\n",
        "                                 for split_info in self.feature_importance_list if token in split_info['feature_importance']]\n",
        "\n",
        "            # Sort this list by the absolute value of the importance in descending order\n",
        "            sorted_token_importances = sorted(token_importances, key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "            # Print the sorted importances for each token\n",
        "            for test_sample, importance in sorted_token_importances:\n",
        "                print(f\"Test Sample: {test_sample},  Strength: {importance}\")\n",
        "        return\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        overall_r2 = r2_score(self.results_df['actual'], self.results_df['predicted'])\n",
        "        overall_mse = mean_squared_error(self.results_df['actual'], self.results_df['predicted'])\n",
        "        overall_rmse = np.sqrt(overall_mse)\n",
        "        overall_mae = mean_absolute_error(self.results_df['actual'], self.results_df['predicted'])\n",
        "        ranked_results = self.results_df.sort_values(by='MAE', ascending=True)\n",
        "        return {\n",
        "        'info': f\"LOOCV Results for {self.model} {self.vectorizer}\",\n",
        "        'results': ranked_results[['name', 'actual', 'predicted', 'MAE']].to_string(index=False),\n",
        "        'overall_r2': overall_r2,\n",
        "        'overall_mse': overall_mse,\n",
        "        'overall_rmse': overall_rmse,\n",
        "        'overall_mae': overall_mae\n",
        "                }\n",
        "\n"
      ],
      "metadata": {
        "id": "vT2YYm_YwcyL"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data"
      ],
      "metadata": {
        "id": "ixE_LMpSePGT"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizers = [CountVectorizer(ngram_range=(1,1)), TfidfVectorizer(ngram_range=(1,1)), CountVectorizer(ngram_range=(2,2)), TfidfVectorizer(ngram_range=(2,2))]\n",
        "\n",
        "models = [\n",
        "    LinearRegression(),\n",
        "    Lasso(),\n",
        "    ElasticNet(),\n",
        "    Ridge(),\n",
        "    DecisionTreeRegressor(),\n",
        "    RandomForestRegressor(),\n",
        "    KNeighborsRegressor(),\n",
        "    SVR(kernel='linear'),\n",
        "    SVR(kernel=\"rbf\"),\n",
        "    PoissonRegressor(),\n",
        "    #GradientBoostingRegressor(),\n",
        "    BaggingRegressor(),\n",
        "    AdaBoostRegressor(),\n",
        "    #HistGradientBoostingRegressor()\n",
        "]\n"
      ],
      "metadata": {
        "id": "qgy8mBomiV4j"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "winners = []\n",
        "for model in models:\n",
        "  for vectorizer in vectorizers:\n",
        "    test = TextRegressionModel(train_data, target_column='score', text_column='clean_text', vectorizer=vectorizer, model=model)\n",
        "    test.perform_loocv()\n",
        "    t = test.evaluate_model()\n",
        "    r2 = t[\"overall_r2\"]\n",
        "    if r2>0.5:\n",
        "      winners.append(t)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5tVQvpfoIxM"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info:\n",
        "LOOCV Results for ElasticNet() CountVectorizer()\n",
        "results:\n",
        "    name  actual  predicted      MAE\n",
        "bernardo    35.0  35.144126 0.144126\n",
        "ridgeway    19.0  19.714079 0.714079\n",
        "    gacy    27.0  26.265473 0.734527\n",
        "  kemper    26.0  24.874667 1.125333\n",
        "   marsh    35.8  34.036246 1.763754\n",
        "   bundy    34.0  36.648760 2.648760\n",
        "  dahmer    23.0  26.873856 3.873856\n",
        "mitchell    34.0  38.616285 4.616285\n",
        "   wayne    40.0  34.122665 5.877335\n",
        "    carl    36.0  44.118066 8.118066\n",
        "overall_r2:\n",
        "0.637832007578986\n",
        "overall_mse:\n",
        "14.922625092518496\n",
        "overall_rmse:\n",
        "3.8629813735660825\n",
        "overall_mae:\n",
        "2.9616120845826357\n",
        "\n",
        "\n",
        "info:\n",
        "LOOCV Results for Lasso() CountVectorizer()\n",
        "results:\n",
        "    name  actual  predicted      MAE\n",
        "bernardo    35.0  35.248499 0.248499\n",
        "  kemper    26.0  25.351551 0.648449\n",
        "ridgeway    19.0  19.808522 0.808522\n",
        "   bundy    34.0  34.957588 0.957588\n",
        "    gacy    27.0  26.011289 0.988711\n",
        "   marsh    35.8  33.493328 2.306672\n",
        "  dahmer    23.0  26.826342 3.826342\n",
        "mitchell    34.0  38.772289 4.772289\n",
        "   wayne    40.0  34.201087 5.798913\n",
        "    carl    36.0  44.077803 8.077803\n",
        "overall_r2:\n",
        "0.6489502456457403\n",
        "overall_mse:\n",
        "14.464513658511176\n",
        "overall_rmse:\n",
        "3.803224113631903\n",
        "overall_mae:\n",
        "2.843378831244703\n",
        "\n",
        "\n",
        "info:\n",
        "LOOCV Results for ElasticNet() CountVectorizer(ngram_range=(2, 2))\n",
        "results:\n",
        "    name  actual  predicted      MAE\n",
        "  dahmer    23.0  23.701694 0.701694\n",
        "mitchell    34.0  35.901163 1.901163\n",
        "    gacy    27.0  29.036768 2.036768\n",
        "   bundy    34.0  31.901030 2.098970\n",
        "  kemper    26.0  23.802226 2.197774\n",
        "bernardo    35.0  32.501906 2.498094\n",
        "   marsh    35.8  33.112114 2.687886\n",
        "    carl    36.0  39.586108 3.586108\n",
        "ridgeway    19.0  23.829672 4.829672\n",
        "   wayne    40.0  34.271181 5.728819\n",
        "overall_r2:\n",
        "0.757395999757643\n",
        "overall_mse:\n",
        "9.996158184385981\n",
        "overall_rmse:\n",
        "3.1616701574304016\n",
        "overall_mae:\n",
        "2.826694832770637\n",
        "\n",
        "\n",
        "info:\n",
        "LOOCV Results for Lasso() CountVectorizer(ngram_range=(2, 2))\n",
        "results:\n",
        "    name  actual  predicted      MAE\n",
        "  dahmer    23.0  22.784588 0.215412\n",
        "   bundy    34.0  34.412090 0.412090\n",
        "    gacy    27.0  28.884616 1.884616\n",
        "bernardo    35.0  32.898529 2.101471\n",
        "mitchell    34.0  36.460480 2.460480\n",
        "   marsh    35.8  33.307327 2.492673\n",
        "  kemper    26.0  23.364392 2.635608\n",
        "    carl    36.0  39.410318 3.410318\n",
        "ridgeway    19.0  22.469374 3.469374\n",
        "   wayne    40.0  34.497808 5.502192\n",
        "overall_r2:\n",
        "0.8025926496279935\n",
        "overall_mse:\n",
        "8.133893501788009\n",
        "overall_rmse:\n",
        "2.8519981594994075\n",
        "overall_mae:\n",
        "2.4584234565094314"
      ],
      "metadata": {
        "id": "okJRsvF7odWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sorted(winners, key=lambda i: i[\"overall_r2\"]):\n",
        "  for k,v in i.items():\n",
        "    print(f\"{k}:\")\n",
        "    print(v)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ViHtEOO8jT",
        "outputId": "37ec85f5-54e2-4aa9-fd21-f8f378a331a7"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "info:\n",
            "LOOCV Results for ElasticNet() CountVectorizer()\n",
            "results:\n",
            "    name  actual  predicted      MAE\n",
            "bernardo    35.0  35.144126 0.144126\n",
            "ridgeway    19.0  19.714079 0.714079\n",
            "    gacy    27.0  26.265473 0.734527\n",
            "  kemper    26.0  24.874667 1.125333\n",
            "   marsh    35.8  34.036246 1.763754\n",
            "   bundy    34.0  36.648760 2.648760\n",
            "  dahmer    23.0  26.873856 3.873856\n",
            "mitchell    34.0  38.616285 4.616285\n",
            "   wayne    40.0  34.122665 5.877335\n",
            "    carl    36.0  44.118066 8.118066\n",
            "overall_r2:\n",
            "0.637832007578986\n",
            "overall_mse:\n",
            "14.922625092518496\n",
            "overall_rmse:\n",
            "3.8629813735660825\n",
            "overall_mae:\n",
            "2.9616120845826357\n",
            "\n",
            "\n",
            "info:\n",
            "LOOCV Results for Lasso() CountVectorizer()\n",
            "results:\n",
            "    name  actual  predicted      MAE\n",
            "bernardo    35.0  35.248499 0.248499\n",
            "  kemper    26.0  25.351551 0.648449\n",
            "ridgeway    19.0  19.808522 0.808522\n",
            "   bundy    34.0  34.957588 0.957588\n",
            "    gacy    27.0  26.011289 0.988711\n",
            "   marsh    35.8  33.493328 2.306672\n",
            "  dahmer    23.0  26.826342 3.826342\n",
            "mitchell    34.0  38.772289 4.772289\n",
            "   wayne    40.0  34.201087 5.798913\n",
            "    carl    36.0  44.077803 8.077803\n",
            "overall_r2:\n",
            "0.6489502456457403\n",
            "overall_mse:\n",
            "14.464513658511176\n",
            "overall_rmse:\n",
            "3.803224113631903\n",
            "overall_mae:\n",
            "2.843378831244703\n",
            "\n",
            "\n",
            "info:\n",
            "LOOCV Results for ElasticNet() CountVectorizer(ngram_range=(2, 2))\n",
            "results:\n",
            "    name  actual  predicted      MAE\n",
            "  dahmer    23.0  23.701694 0.701694\n",
            "mitchell    34.0  35.901163 1.901163\n",
            "    gacy    27.0  29.036768 2.036768\n",
            "   bundy    34.0  31.901030 2.098970\n",
            "  kemper    26.0  23.802226 2.197774\n",
            "bernardo    35.0  32.501906 2.498094\n",
            "   marsh    35.8  33.112114 2.687886\n",
            "    carl    36.0  39.586108 3.586108\n",
            "ridgeway    19.0  23.829672 4.829672\n",
            "   wayne    40.0  34.271181 5.728819\n",
            "overall_r2:\n",
            "0.757395999757643\n",
            "overall_mse:\n",
            "9.996158184385981\n",
            "overall_rmse:\n",
            "3.1616701574304016\n",
            "overall_mae:\n",
            "2.826694832770637\n",
            "\n",
            "\n",
            "info:\n",
            "LOOCV Results for Lasso() CountVectorizer(ngram_range=(2, 2))\n",
            "results:\n",
            "    name  actual  predicted      MAE\n",
            "  dahmer    23.0  22.784588 0.215412\n",
            "   bundy    34.0  34.412090 0.412090\n",
            "    gacy    27.0  28.884616 1.884616\n",
            "bernardo    35.0  32.898529 2.101471\n",
            "mitchell    34.0  36.460480 2.460480\n",
            "   marsh    35.8  33.307327 2.492673\n",
            "  kemper    26.0  23.364392 2.635608\n",
            "    carl    36.0  39.410318 3.410318\n",
            "ridgeway    19.0  22.469374 3.469374\n",
            "   wayne    40.0  34.497808 5.502192\n",
            "overall_r2:\n",
            "0.8025926496279935\n",
            "overall_mse:\n",
            "8.133893501788009\n",
            "overall_rmse:\n",
            "2.8519981594994075\n",
            "overall_mae:\n",
            "2.4584234565094314\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_check = TextRegressionModel(train_data, target_column='score', text_column='clean_text', vectorizer=CountVectorizer(), model=Lasso())\n",
        "lasso_check.perform_loocv()\n",
        "lasso_check.get_coefficients()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udtK-N0bXdHJ",
        "outputId": "cddb256d-7838-4e5e-de4b-4acb1edd3bcb"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Token: was \n",
            "Top performing feature in 10/10 models | Average Strength: -0.28791459779137324\n",
            "Test Sample: mitchell,  Strength: -0.3415503895369341\n",
            "Test Sample: gacy,  Strength: -0.32519851656160603\n",
            "Test Sample: bundy,  Strength: -0.315799205600534\n",
            "Test Sample: kemper,  Strength: -0.31545620478839653\n",
            "Test Sample: dahmer,  Strength: -0.3129697038410047\n",
            "Test Sample: bernardo,  Strength: -0.31120015395030975\n",
            "Test Sample: ridgeway,  Strength: -0.2956437338466488\n",
            "Test Sample: marsh,  Strength: -0.28972556709169117\n",
            "Test Sample: wayne,  Strength: -0.2064881919409591\n",
            "Test Sample: carl,  Strength: -0.1651143107556484\n",
            "\n",
            "Token: like \n",
            "Top performing feature in 9/10 models | Average Strength: 0.01914764540030129\n",
            "Test Sample: wayne,  Strength: 0.04281761751233612\n",
            "Test Sample: bundy,  Strength: 0.04028041719449961\n",
            "Test Sample: carl,  Strength: -0.03627253961572249\n",
            "Test Sample: kemper,  Strength: 0.0321273749518544\n",
            "Test Sample: ridgeway,  Strength: 0.027116296014817874\n",
            "Test Sample: dahmer,  Strength: 0.021758446111858783\n",
            "Test Sample: bernardo,  Strength: 0.020592341934804453\n",
            "Test Sample: gacy,  Strength: 0.018038319452590882\n",
            "Test Sample: mitchell,  Strength: 0.005870535045671936\n",
            "\n",
            "Token: uh \n",
            "Top performing feature in 9/10 models | Average Strength: -0.03467422405457992\n",
            "Test Sample: wayne,  Strength: -0.05038346591570387\n",
            "Test Sample: carl,  Strength: -0.044211293058212475\n",
            "Test Sample: bundy,  Strength: -0.03490330186355421\n",
            "Test Sample: bernardo,  Strength: -0.03444554336322272\n",
            "Test Sample: mitchell,  Strength: -0.032352330804534174\n",
            "Test Sample: gacy,  Strength: -0.031277279655131586\n",
            "Test Sample: marsh,  Strength: -0.03041287127772756\n",
            "Test Sample: ridgeway,  Strength: -0.029616796177864658\n",
            "Test Sample: kemper,  Strength: -0.024465134375267983\n",
            "\n",
            "Token: it \n",
            "Top performing feature in 8/10 models | Average Strength: -0.03292508994432677\n",
            "Test Sample: carl,  Strength: -0.050225792845907585\n",
            "Test Sample: marsh,  Strength: -0.04178451209991334\n",
            "Test Sample: kemper,  Strength: -0.03576021809976869\n",
            "Test Sample: ridgeway,  Strength: -0.03519487694083738\n",
            "Test Sample: bundy,  Strength: -0.03382087584815342\n",
            "Test Sample: mitchell,  Strength: -0.03341072020883773\n",
            "Test Sample: bernardo,  Strength: -0.020945439252166995\n",
            "Test Sample: gacy,  Strength: -0.012258284259028984\n",
            "\n",
            "Token: the \n",
            "Top performing feature in 7/10 models | Average Strength: -0.017969540184386186\n",
            "Test Sample: carl,  Strength: -0.0774855150038717\n",
            "Test Sample: mitchell,  Strength: 0.016894865989542224\n",
            "Test Sample: ridgeway,  Strength: -0.015333673823331258\n",
            "Test Sample: gacy,  Strength: -0.014960816581380038\n",
            "Test Sample: bernardo,  Strength: -0.013755938570270522\n",
            "Test Sample: kemper,  Strength: -0.010989945447504638\n",
            "Test Sample: wayne,  Strength: -0.010155757853887356\n",
            "\n",
            "Token: we \n",
            "Top performing feature in 7/10 models | Average Strength: 0.2905868207542737\n",
            "Test Sample: bundy,  Strength: 0.3385787660073032\n",
            "Test Sample: marsh,  Strength: 0.338460373432996\n",
            "Test Sample: kemper,  Strength: 0.2985854410645113\n",
            "Test Sample: bernardo,  Strength: 0.29667953156003773\n",
            "Test Sample: ridgeway,  Strength: 0.2820789661178574\n",
            "Test Sample: gacy,  Strength: 0.2546995189366488\n",
            "Test Sample: dahmer,  Strength: 0.225025148160562\n",
            "\n",
            "Token: he \n",
            "Top performing feature in 7/10 models | Average Strength: 0.10525925284564973\n",
            "Test Sample: mitchell,  Strength: 0.2769926814542421\n",
            "Test Sample: bernardo,  Strength: 0.1035480553525187\n",
            "Test Sample: kemper,  Strength: 0.09509349151794091\n",
            "Test Sample: gacy,  Strength: 0.09230861706104501\n",
            "Test Sample: ridgeway,  Strength: 0.08626264276694129\n",
            "Test Sample: dahmer,  Strength: 0.08074947297032053\n",
            "Test Sample: marsh,  Strength: 0.001859808796539431\n",
            "\n",
            "Token: you \n",
            "Top performing feature in 3/10 models | Average Strength: 0.006927329177646396\n",
            "Test Sample: wayne,  Strength: 0.019647448089506397\n",
            "Test Sample: carl,  Strength: 0.00895058004181731\n",
            "Test Sample: bundy,  Strength: -0.007816040598384519\n",
            "\n",
            "Token: my \n",
            "Top performing feature in 2/10 models | Average Strength: -0.13020917837610618\n",
            "Test Sample: carl,  Strength: -0.1313523741771802\n",
            "Test Sample: wayne,  Strength: -0.12906598257503218\n",
            "\n",
            "Token: her \n",
            "Top performing feature in 2/10 models | Average Strength: -0.06728131464487201\n",
            "Test Sample: carl,  Strength: -0.09874736817193731\n",
            "Test Sample: dahmer,  Strength: -0.0358152611178067\n",
            "\n",
            "Token: of \n",
            "Top performing feature in 2/10 models | Average Strength: 0.004876513837453253\n",
            "Test Sample: mitchell,  Strength: 0.03546612979473499\n",
            "Test Sample: carl,  Strength: -0.025713102119828486\n",
            "\n",
            "Token: and \n",
            "Top performing feature in 2/10 models | Average Strength: -0.014261340421153358\n",
            "Test Sample: dahmer,  Strength: -0.0178748784995239\n",
            "Test Sample: marsh,  Strength: -0.010647802342782814\n",
            "\n",
            "Token: that \n",
            "Top performing feature in 1/10 models | Average Strength: 0.041468947752112385\n",
            "Test Sample: wayne,  Strength: 0.041468947752112385\n",
            "\n",
            "Token: not \n",
            "Top performing feature in 1/10 models | Average Strength: -0.003056680313406563\n",
            "Test Sample: bundy,  Strength: -0.003056680313406563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Token: and and\n",
        "Top performing feature in 9/10 models | Average Strength: -0.29357909154040557\n",
        "Test Sample: bernardo,  Strength: -0.4435550291168784\n",
        "Test Sample: gacy,  Strength: -0.3764228605323173\n",
        "Test Sample: dahmer,  Strength: -0.3676888028632868\n",
        "Test Sample: carl,  Strength: -0.3587643419616539\n",
        "Test Sample: bundy,  Strength: -0.3376406755373605\n",
        "Test Sample: mitchell,  Strength: -0.2970501974800098\n",
        "Test Sample: marsh,  Strength: -0.24605658787025422\n",
        "Test Sample: ridgeway,  Strength: -0.11153288272254681\n",
        "Test Sample: kemper,  Strength: -0.1035004457793427\n"
      ],
      "metadata": {
        "id": "z15RpiGUstKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_check = TextRegressionModel(train_data, target_column='score', text_column='clean_text', vectorizer=CountVectorizer(ngram_range= (2,2)), model=Lasso())\n",
        "lasso_check.perform_loocv()\n",
        "lasso_check.get_coefficients()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptxJvf9tfft-",
        "outputId": "f078a92b-a1be-4d7f-8182-238c91cd127f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Token: it was \n",
            "Top performing feature in 10/10 models | Average Strength: -1.0246022544218585\n",
            "Test Sample: kemper,  Strength: -1.1466792659839617\n",
            "Test Sample: carl,  Strength: -1.1075503017551414\n",
            "Test Sample: mitchell,  Strength: -1.0624943341600304\n",
            "Test Sample: bundy,  Strength: -1.0532740567648367\n",
            "Test Sample: dahmer,  Strength: -1.0406091481261253\n",
            "Test Sample: gacy,  Strength: -1.022153274012203\n",
            "Test Sample: marsh,  Strength: -1.004597789704983\n",
            "Test Sample: bernardo,  Strength: -1.000131276562792\n",
            "Test Sample: ridgeway,  Strength: -0.9379491739182455\n",
            "Test Sample: wayne,  Strength: -0.8705839232302678\n",
            "\n",
            "Token: and and \n",
            "Top performing feature in 9/10 models | Average Strength: -0.29357909154040557\n",
            "Test Sample: bernardo,  Strength: -0.4435550291168784\n",
            "Test Sample: gacy,  Strength: -0.3764228605323173\n",
            "Test Sample: dahmer,  Strength: -0.3676888028632868\n",
            "Test Sample: carl,  Strength: -0.3587643419616539\n",
            "Test Sample: bundy,  Strength: -0.3376406755373605\n",
            "Test Sample: mitchell,  Strength: -0.2970501974800098\n",
            "Test Sample: marsh,  Strength: -0.24605658787025422\n",
            "Test Sample: ridgeway,  Strength: -0.11153288272254681\n",
            "Test Sample: kemper,  Strength: -0.1035004457793427\n",
            "\n",
            "Token: of the \n",
            "Top performing feature in 8/10 models | Average Strength: -0.11072621971061847\n",
            "Test Sample: carl,  Strength: -0.2340410073971165\n",
            "Test Sample: ridgeway,  Strength: -0.147769115658214\n",
            "Test Sample: bundy,  Strength: -0.11888882230989412\n",
            "Test Sample: dahmer,  Strength: -0.11500907069608475\n",
            "Test Sample: wayne,  Strength: -0.07888735856798118\n",
            "Test Sample: bernardo,  Strength: -0.07705513050570253\n",
            "Test Sample: marsh,  Strength: -0.0655323362930973\n",
            "Test Sample: kemper,  Strength: -0.04862691625685742\n",
            "\n",
            "Token: we have \n",
            "Top performing feature in 8/10 models | Average Strength: 0.2748168361340782\n",
            "Test Sample: marsh,  Strength: 0.4088839162770549\n",
            "Test Sample: ridgeway,  Strength: 0.3387120959610029\n",
            "Test Sample: kemper,  Strength: 0.32647793290570715\n",
            "Test Sample: bernardo,  Strength: 0.298576344897492\n",
            "Test Sample: dahmer,  Strength: 0.27260775112074914\n",
            "Test Sample: bundy,  Strength: 0.2620897828439982\n",
            "Test Sample: gacy,  Strength: 0.16543222350430153\n",
            "Test Sample: mitchell,  Strength: 0.12575464156231975\n",
            "\n",
            "Token: dont know \n",
            "Top performing feature in 7/10 models | Average Strength: 0.07775191349124158\n",
            "Test Sample: wayne,  Strength: 0.20013065187456222\n",
            "Test Sample: kemper,  Strength: 0.15338343501921192\n",
            "Test Sample: bernardo,  Strength: 0.06526155008066745\n",
            "Test Sample: bundy,  Strength: 0.04536092560035008\n",
            "Test Sample: dahmer,  Strength: 0.03933622267265464\n",
            "Test Sample: mitchell,  Strength: 0.020913126462147037\n",
            "Test Sample: gacy,  Strength: 0.019877482729097822\n",
            "\n",
            "Token: in the \n",
            "Top performing feature in 6/10 models | Average Strength: -0.068930379023341\n",
            "Test Sample: carl,  Strength: -0.111265918825869\n",
            "Test Sample: kemper,  Strength: -0.09119616912822176\n",
            "Test Sample: mitchell,  Strength: -0.08790999995373687\n",
            "Test Sample: ridgeway,  Strength: -0.08561409930822582\n",
            "Test Sample: gacy,  Strength: -0.03727875625038\n",
            "Test Sample: dahmer,  Strength: -0.00031733067361248453\n",
            "\n",
            "Token: you guys \n",
            "Top performing feature in 5/10 models | Average Strength: 0.0371878648252221\n",
            "Test Sample: marsh,  Strength: 0.04865719196490836\n",
            "Test Sample: dahmer,  Strength: 0.047174615299977074\n",
            "Test Sample: gacy,  Strength: 0.04258808061135794\n",
            "Test Sample: bundy,  Strength: 0.03376384574456375\n",
            "Test Sample: mitchell,  Strength: 0.013755590505303361\n",
            "\n",
            "Token: the lord \n",
            "Top performing feature in 2/10 models | Average Strength: -0.09406050078803968\n",
            "Test Sample: gacy,  Strength: -0.11825263210225267\n",
            "Test Sample: kemper,  Strength: -0.06986836947382669\n",
            "\n",
            "Token: and uh \n",
            "Top performing feature in 1/10 models | Average Strength: -0.33004423504664543\n",
            "Test Sample: wayne,  Strength: -0.33004423504664543\n",
            "\n",
            "Token: for the \n",
            "Top performing feature in 1/10 models | Average Strength: -0.007021386914084693\n",
            "Test Sample: wayne,  Strength: -0.007021386914084693\n",
            "\n",
            "Token: you know \n",
            "Top performing feature in 1/10 models | Average Strength: -0.028823824843559224\n",
            "Test Sample: carl,  Strength: -0.028823824843559224\n",
            "\n",
            "Token: and they \n",
            "Top performing feature in 1/10 models | Average Strength: -0.04372000286387307\n",
            "Test Sample: mitchell,  Strength: -0.04372000286387307\n",
            "\n",
            "Token: the the \n",
            "Top performing feature in 1/10 models | Average Strength: -0.06429363740290588\n",
            "Test Sample: ridgeway,  Strength: -0.06429363740290588\n",
            "\n",
            "Token: to the \n",
            "Top performing feature in 1/10 models | Average Strength: -0.03554282455701668\n",
            "Test Sample: ridgeway,  Strength: -0.03554282455701668\n",
            "\n",
            "Token: she was \n",
            "Top performing feature in 1/10 models | Average Strength: -0.04826198971025543\n",
            "Test Sample: marsh,  Strength: -0.04826198971025543\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}